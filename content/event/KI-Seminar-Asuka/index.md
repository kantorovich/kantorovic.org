---
title: "Bregman divergence regularization of optimal transport problems on a finite set"
event: KI Seminar
location: "Online (zoom)"
registration_info: |
  Sign up for the [mailing list](https://math.us8.list-manage.com/subscribe/post?u=c9cc3beec9fa57d7299ac161c&id=845fe9abdc) to receive the connection details
speaker:
  name: Asuka Takatsu
  institution: Tokyo Metropolitan University
  url: https://sites.google.com/site/asukatakatsu/
abstract: |
  In optimal transport problems on a finite set, one successful approach to reducing its computational burden 
  is the regularization by the Kullback-Leibler divergence. Then a natural question arises: Are other divergences 
  not admissible for regularization? What kinds of properties are required for divergences? I introduce required 
  properties for Bregman divergences and provide a non-asymptotic error estimate for the optimal transport problem 
  regularized by such Bregman divergences. This convergence is possibly faster than exponential decay as the 
  regularized parameter goes to zero. 

  This talk is based on joint work with Koya Sakakibara (Okayama U. of Science) and Keiichi Morikuni (U. of Tsukuba).

summary:
authors:

tags: ['']
categories: ['event']
date: 2023-01-26T10:00:00-08:00
publishDate: 2022-09-21T00:00:00-08:00
lastmod: 2023-01-13T00:00:00-08:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
url_video: 
url_slides: 
---%  
